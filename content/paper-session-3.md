
+++
date = '2025-01-24T21:30:10-05:00'
draft = false
title = 'Paper Session 3'
+++

Friday, March 14, 2025  
**Room 820**  
10:20am - 11:40am  

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/X8nk2uWSe0g?si=ekKEYvuPxezCnxOw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## The code as the expression of its own vitalism

[Luis Alfonso Tamagnini](/bios/#luis-alfonso-tamagnini)  
10:20am

*Keywords: computational creativity, music performance, interactive music systems, live coding, simulation, software studies, media theory*

In her book My Mother Was a Computer: Digital Subjects and Literary Texts, literary theorist and critic Katherine Hayles posits that; as computers are increasingly understood, and modeled after “expressive mediums” like writing, they begin to acquire the familiar and potent capability of writing not merely to express thought but actively to constitute it.

The code of the future will become more like the writing of the past – or rather, in the future there will be an as-yet-concealed hybrid of code and writing.

It is on this path on which I write this self essay about how I wrote and how I write computer music code. In it, I wonder about how formal language permeates the concepts of score, musical instrument, composition and performance among others. These structures become not only an expression of an abstract process or thought, but also an expression of itself, or of its own "vitalism"

Furthermore, I allow myself to explore the live coding technique as a way to interact with such complex entities.

## The New Pulsar Generator (nuPG)

[Marcin Pietruszewski](/bios/#marcin-pietruszewski)  
10:40am

Abstract Needed

## Live-Coding and AI Assistance for Dynamic Musical Instrument Design in SuperCollider

[Steph OHara](/bios/#steph-ohara)  
11am

This research explores live-coding techniques for developing accessible, interactive musical instruments within SuperCollider. It focuses on an enhanced real-time co-design process providing instantaneous adaptation to users' evolving needs, particularly for music students with disabilities. The approach integrates dynamic code manipulation, AI assistance, and the adaptation of Airsticks, a gestural musical instrument.

## Stecker

[Dennis Scheiba](/bios/#dennis-scheiba)  
11:20am

Stecker is a project which enhances the sound generating nature of SuperCollider by providing a native way of distributing and receiving low-latency audio and data-streams over the internet within SuperCollider using WebRTC.

This is achieved by providing a set of  UGens which can receive and transmit such signals and also a web server, which takes care of the administration and distribution of said signals and allows users to listen or generate streams from within their browser.

Stecker is inspired by JITLib and live coding in general, and is also intended to serve as a platform by providing "community radio stations" which allow for on-the-fly remixing as well as establishing and exploring new places for acoustic performances and sources.

